{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b9eaf",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "Read the data in as a dataframe using pandas. The data file is called: \"African_data.txt\". The data include [bioclimatic variables](https://www.worldclim.org/data/bioclim.html) (the average and standard deviation across a species' range), the minimum and maximum latitude and longitude of the species range, and the area of the species range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31597df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Africa_data = pd.read_csv(\"Africa_data.txt\", sep=\"\\t\", header=0)\n",
    "Africa_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a81ef4",
   "metadata": {},
   "source": [
    "# Change Red List Status Labelling and remove some rows\n",
    "\n",
    "The below code will just modify the response variable to match the categories used in the paper (e.g., the table lists Near Threatened species as (LR/nt) and vulnurable species as (LR/cd) where cd stands for conservation dependent.)\n",
    "\n",
    "We also remove rows with no red list status defined, and rows where there were fewer than four GPS points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition to identify rows where 'Red.List.status' is \"LR/nt\"\n",
    "condition = Africa_data['Red.List.status'] == \"LR/nt\"\n",
    "# Modify the values based on the condition\n",
    "Africa_data.loc[condition, 'Red.List.status'] = \"NT\"\n",
    "\n",
    "# Condition to identify rows where 'Red.List.status' is \"LR/cd\"\n",
    "condition = Africa_data['Red.List.status'] == \"LR/cd\"\n",
    "# Modify the values based on the condition\n",
    "Africa_data.loc[condition, 'Red.List.status'] = \"VU\"\n",
    "\n",
    "# Condition to identify rows where 'Red.List.status' is \"LR/lc\"\n",
    "condition = Africa_data['Red.List.status'] == \"LR/lc\"\n",
    "# Modify the values based on the condition\n",
    "Africa_data.loc[condition, 'Red.List.status'] = \"LC\"\n",
    "\n",
    "# remove rows without a defined red list status\n",
    "filtered_Africa_data = Africa_data.dropna(subset=['Red.List.status'])\n",
    "\n",
    "# remove rows with fewer than 4 samples\n",
    "filtered_Africa_data = filtered_Africa_data[filtered_Africa_data['n.gps'] >= 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87098998",
   "metadata": {},
   "source": [
    "# Check how many observations belong in each category\n",
    "\n",
    "Random Forest Classifiers may not perform well when we have different numbers of observations in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7a832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_counts = filtered_Africa_data['Red.List.status'].value_counts().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "status_counts.columns = ['Red List Status', 'Count']\n",
    "\n",
    "# Display the table\n",
    "print(status_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9b309",
   "metadata": {},
   "source": [
    "# Add variable indicating whether a species is LC or not LC\n",
    "\n",
    "Notice that we have the most observations for least concern (LC). The authors of this paper decided to only try to predict whether a species was least concern or not. Below, we add a response column that only includes 'LC' and 'NonLC'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09491cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_Africa_data['Response'] = np.where(filtered_Africa_data['Red.List.status'] == 'LC', 'LC', 'NonLC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a666ff",
   "metadata": {},
   "source": [
    "# Prepare dataset for training\n",
    "\n",
    "Next, we prepare our dataset for training by removing columns that we won't use, separating out our labels and features, and splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0503bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to remove during trainign (i.e., columns we don't want to use as features or respjonses)\n",
    "columns_to_remove = ['name', 'n.gps', 'continents', 'dist']\n",
    "\n",
    "# Removing columns using drop()\n",
    "X = filtered_Africa_data.drop(columns=columns_to_remove)\n",
    "\n",
    "# separe labels and features\n",
    "y = X['Response']\n",
    "X = X.drop('Response', axis=1)\n",
    "\n",
    "# separate original labels\n",
    "y_full = X['Red.List.status']\n",
    "X = X.drop('Red.List.status', axis=1)\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "# NOTE: DO NOT TOUCH THE TESTING SET \n",
    "# NOTE: DO NOT CHANGE THESE RANDOM_STATE VARIABLES\n",
    "X_train, X_test_val, y_train, y_test_val, y_full_train, y_full_test_val = train_test_split(X, y, y_full, test_size=0.4, random_state=40)\n",
    "X_test, X_val, y_test, y_val, y_full_test, y_full_val = train_test_split(X_test_val, y_test_val, y_full_test_val, test_size=0.5, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1cbb75",
   "metadata": {},
   "source": [
    "# Scale\n",
    "\n",
    "Let's scale our features to put everything on the same scale (this can be important when evaluating feature importance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351060a",
   "metadata": {},
   "source": [
    "# Train the Random Forest Classifier, and check the out of bag score.\n",
    "\n",
    "The out of bag score is the accuracy, not the error. To get the error, subtract this from one.\n",
    "\n",
    "**Change**: Try changing the number of estimators (i.e., trees) and explore how this impacts accuracy.\n",
    "\n",
    "**6990**: Write a for loop to explore different numbers of estimators, and choose the best number to use in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the classifiers\n",
    "randomforest = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "randomforest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print the oob score\n",
    "print(randomforest.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bd547",
   "metadata": {},
   "source": [
    "# Make Predictions on the training data and assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad21a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_train = randomforest.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    randomforest, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d27bb8",
   "metadata": {},
   "source": [
    "# Make Predictions on the test data and assess performance\n",
    "\n",
    "**Add**: Add code to make predictions and assess performance on the test data. Include accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c70b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f75caf28",
   "metadata": {},
   "source": [
    "# Impurity variable Importance\n",
    "\n",
    "Below, we calculate feature importance using GINI impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "feature_importances = pd.Series(randomforest.feature_importances_, index=X_train.columns).sort_values(ascending=False)[0:5]\n",
    "\n",
    "# Plot a simple bar chart\n",
    "feature_importances.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1ff4b",
   "metadata": {},
   "source": [
    "# Permutation Variable Importance\n",
    "We will now calculate Mean Decrease in Accuracy, our permutation measure of importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_feature_importances = permutation_importance(randomforest, X_test_scaled, y_test,\n",
    "                                        n_repeats=50,\n",
    "                                        random_state=0)\n",
    "\n",
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "plot_permutation_feature_importances = pd.Series(permutation_feature_importances['importances_mean'], index=X_test.columns).sort_values(ascending=False)[0:5]\n",
    "\n",
    "# Plot a simple bar chart\n",
    "plot_permutation_feature_importances.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a48c43",
   "metadata": {},
   "source": [
    "# You try it!\n",
    "\n",
    "Try building a Random Forest classifier that Considers all the classes instead of collapsing things into LC or Non-LC.\n",
    "\n",
    "I have already prepared the labels for you (y_full_train, y_full_test, y_full_val).\n",
    "\n",
    "You will need to do the following:\n",
    "1. Train the Random Forest Classifier, and check the out of bag score.\n",
    "2. Make Predictions on the training data and assess performance.\n",
    "3. Make Predictions on the testing data and assess performance.\n",
    "4. Plot impurity variable importance.\n",
    "5. Plot permutation variable importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b5234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a3e3483",
   "metadata": {},
   "source": [
    "# Final measure of accuracy\n",
    "\n",
    "After you have decided which model you favor, measure the accuracy using the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cb8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
