{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the Data\n",
    "\n",
    "For this activity, we will use the data from the Herbarium Challenge described in [Little et al. (2020)](https://bsapubs.onlinelibrary.wiley.com/doi/pdf/10.1002/aps3.11365).\n",
    "\n",
    "The data are a set of images of herbarium specimens labeled by species.\n",
    "\n",
    "The training data consists of 34225 images and labels. The labels indicate to which of 683 species the imaged specimens belong. The validation data consists of 2679 images and labels.\n",
    "\n",
    "In the interest of time, we will only consider the five species with the mostimages. So, our training data will consist of 2575 images and labels and our validation data will consist of 174 images and labels.\n",
    "\n",
    "We will not use testing data here, because the authors did not provide the labels. Imagine that the authors will evaluate your model on the testing data once you turn a finalized model over to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define parameters\n",
    "batch_size = 32\n",
    "image_height = 150\n",
    "image_width = 150\n",
    "num_classes = 5\n",
    "\n",
    "# Step 2: Define data preprocessing function\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_height, image_width])\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0,1]\n",
    "    return image, label\n",
    "\n",
    "with tarfile.open('small-train.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall()\n",
    "\n",
    "with tarfile.open('small-validation.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall()\n",
    "\n",
    "# Step 3: Load and preprocess the training dataset\n",
    "train_data_dir = './small-train/'\n",
    "\n",
    "train_image_paths = []\n",
    "train_labels = []\n",
    "label_count = {}  # Dictionary to store the count of images for each label\n",
    "\n",
    "train_categories = os.listdir(train_data_dir)\n",
    "for category in train_categories:\n",
    "    category_path = os.path.join(train_data_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        label = int(category)\n",
    "        image_files = os.listdir(category_path)\n",
    "        label_count[label] = len(image_files)  # Count the number of images for this label\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(category_path, image_file)\n",
    "            train_image_paths.append(image_path)\n",
    "            train_labels.append(label)\n",
    "\n",
    "# Create a mapping from original labels to new labels (continuous integers starting from 0)\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(train_labels))}\n",
    "\n",
    "# Map the original labels to new labels in the training dataset\n",
    "mapped_train_labels = [label_mapping[label] for label in train_labels]\n",
    "\n",
    "# Create TensorFlow Dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, mapped_train_labels))\n",
    "train_dataset = train_dataset.map(preprocess_image)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_image_paths)).batch(batch_size)\n",
    "\n",
    "# Step 4: Load and preprocess the validation dataset\n",
    "val_data_dir = './small-validation/'\n",
    "\n",
    "val_image_paths = []\n",
    "val_labels = []\n",
    "\n",
    "val_categories = os.listdir(val_data_dir)\n",
    "for category in val_categories:\n",
    "    category_path = os.path.join(val_data_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        label = int(category)\n",
    "        image_files = os.listdir(category_path)\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(category_path, image_file)\n",
    "            val_image_paths.append(image_path)\n",
    "            val_labels.append(label)\n",
    "\n",
    "# Map the original labels to new labels in the validation dataset\n",
    "mapped_val_labels = [label_mapping[label] for label in val_labels]\n",
    "\n",
    "# Create TensorFlow Dataset for validation data\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, mapped_val_labels))\n",
    "val_dataset = val_dataset.map(preprocess_image)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# print size of datasets\n",
    "print('Validation set: %s' % len(val_labels))\n",
    "print('Training set: %s' % len(train_labels))\n",
    "print(\"Range of labels in train_labels:\", min(mapped_train_labels), \"to\", max(mapped_train_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at some images\n",
    "\n",
    "We will view a fiew images from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Display some example images\n",
    "for images, labels in train_dataset.take(1):  # Take 1 batch as an example\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):  # Display 9 example images\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train the CNN\n",
    "\n",
    "Below we define and train a CNN. We evaluate accuracy on a training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(18, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model with validation data\n",
    "history = model.fit(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "\n",
    "# Step 7: Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)  # Set y-axis limit from 0 to 1\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6990 Only\n",
    "Add code to create confusion matrices for your validation and training data. Look back at the FCNN activity for help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
