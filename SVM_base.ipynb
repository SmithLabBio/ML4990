{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import datasets\n",
    "#import pandas as pd\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782811e7",
   "metadata": {},
   "source": [
    "# Read in the Data\n",
    "\n",
    "Read the ants data into a dataframe.\n",
    "\n",
    "**Change**: Change 'filename' to the name of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ants dataset\n",
    "dataframe = pd.read_csv('filename')\n",
    "\n",
    "# replace species names with zeros and ones\n",
    "dataframe['species'] = dataframe['species'].replace('zeteki', 0)\n",
    "dataframe['species'] = dataframe['species'].replace('fovouros', 1)\n",
    "\n",
    "# view data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256ccc0",
   "metadata": {},
   "source": [
    "# Plot the data, and choose variables\n",
    "\n",
    "Now, we will plot the data. You need to choose two features that you want to use to predict species identity. To learn more about what the features are, see the caption of Figure 1 in the paper: https://peerj.com/articles/11622/#fig-1.\n",
    "\n",
    "**Change**: Change the strings 'variable1' and 'variable2' to the variables you want to plot. We are just using variable names in this case, not direct pointers to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418eab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your features, and set species as the target label.\n",
    "label1 = 'variable1'\n",
    "label2 = 'variable2'\n",
    "labeltarget = 'species'\n",
    "\n",
    "# plot the results\n",
    "custom_palette = {0: 'red', 1: 'yellow'}\n",
    "sns.scatterplot(y=label1, x=label2, hue=labeltarget, data=dataframe, palette=custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f1393",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "\n",
    "The code below prepares your data for the rest of the script. Try to understand what each step of the code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataframe to only include our features and target.\n",
    "dataframe_subset = dataframe[[label1,label2,labeltarget]]\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = dataframe_subset.drop(labeltarget, axis=1)\n",
    "y = dataframe_subset[labeltarget]\n",
    "X.head()\n",
    "\n",
    "# Split the dataset into testing, testing, and validation sets \n",
    "# NOTE: DO NOT CHANGE THESE RANDOM_STATE VARIABLES\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.5, random_state=123)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.25, random_state=123)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e85d8",
   "metadata": {},
   "source": [
    "# Logistic Regression: Training\n",
    "\n",
    "Train the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the logistic regression model\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, penalty=None)\n",
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd9463",
   "metadata": {},
   "source": [
    "# Define a function to plot decision boundaries.\n",
    "\n",
    "Below, I have defined a function to plot our decision boundaries. You do not need to modify this code. We will use this function later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfd058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(X, Y, predicted_Y, model, label1, label2):\n",
    "    \"\"\"A function to plot decision boundaries.\"\"\"\n",
    "\n",
    "    # Get decision boundaries by creating a grid of potential x1 and x2 points\n",
    "    h = 0.02  # Step size in the mesh\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    x1x1, x2x2 = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(x2_min, x2_max, h))\n",
    "\n",
    "    # Get predictions for each point in the mesh\n",
    "    Z = model.predict(np.c_[x1x1.ravel(), x2x2.ravel()])\n",
    "    Z = Z.reshape(x1x1.shape)\n",
    "\n",
    "\n",
    "    # Plot the scatter plot\n",
    "    custom_palette = {0: 'red', 1: 'blue'}\n",
    "    scatter = sns.scatterplot(x=X[:,0], y=X[:,1], hue=Y, palette=custom_palette)\n",
    "\n",
    "    # Match contour colors with scatter plot colors\n",
    "    contour = plt.contourf(x1x1, x2x2, Z, cmap=plt.cm.RdYlBu, alpha=0.2)\n",
    "\n",
    "    # Add legend for the scatter plot\n",
    "    scatter.legend()\n",
    "\n",
    "    plt.title('Decision Boundaries')\n",
    "    plt.xlabel(label1)\n",
    "    plt.ylabel(label2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29c29f",
   "metadata": {},
   "source": [
    "# Evaluate the Logistic Regression on the training data.\n",
    "\n",
    "Below, we use several approaches to evaluate our classifier on the training data.\n",
    "* accuracy: The proportion of correctly classified examples.\n",
    "* confusion matrix: Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label being i-th class and predicted label being j-th class.\n",
    "* plot: Shows the true (color of point) and predicted (color of background) values for each item in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ff743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the training set\n",
    "y_pred_train = logreg.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy_train:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_train)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plot_decision_boundaries(X=X_train_scaled, Y=y_train, predicted_Y=y_pred_train, model=logreg, label1=label1, label2=label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55989c10",
   "metadata": {},
   "source": [
    "# Evaluate the Logistic Regression on the testing data.\n",
    "\n",
    "Below, we use several approaches to evaluate our classifier on the testing data.\n",
    "* accuracy: The proportion of correctly classified examples.\n",
    "* confusion matrix: Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label being i-th class and predicted label being j-th class.\n",
    "* plot: Shows the true (color of point) and predicted (color of background) values for each item in the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the testing set\n",
    "y_pred_test = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy_test:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plot_decision_boundaries(X=X_test_scaled, Y=y_test, predicted_Y=y_pred_test, model=logreg, label1=label1, label2=label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1674df3",
   "metadata": {},
   "source": [
    "# Fit Support Vector Machine and evaluate it on the training data\n",
    "\n",
    "Now, we will fit a support vector machine and evaluate it on the training data. \n",
    "\n",
    "**Change**: Change the following things to fit different models (try a few!)\n",
    "* the kernel: polynomial (***poly***) and radial basis function (***rbf***) are available.\n",
    "* degree: When using the polynomical kernel, define the degree of the polynomial as some positive integer >= 1.\n",
    "* C: Regularization parameter. When C is low, the classifier will look for large margins, and will allow for a lot of misclassification. When C is high, the classifier will find a smaller margin, and will penalize misclassification more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdf1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the SVM model\n",
    "svm_model = SVC(kernel='rbf', C=100)  # You can adjust the kernel and C parameter as needed, but to use polynomial, you need to add a degree paramter\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_pred_train_svm = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_svm = accuracy_score(y_train, y_pred_train_svm)\n",
    "conf_matrix_train_svm = confusion_matrix(y_train, y_pred_train_svm)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy_train_svm:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_train_svm)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plot_decision_boundaries(X=X_train_scaled, Y=y_train, predicted_Y=y_pred_train_svm, model=svm_model, label1=label1, label2=label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477ea02",
   "metadata": {},
   "source": [
    "# Fit Support Vector Machine and evaluate it on the testing data\n",
    "\n",
    "There are issues with choosing our model based on performance on three training data. Here, we repeat what we did above, except we evaluate our model on the testing data instead of the training data.\n",
    "\n",
    "**Change**: Change the following things to fit different models (try a few!)\n",
    "* the kernel: polynomial (***poly***) and radial basis function (***rbf***) are available.\n",
    "* degree: When using the polynomical kernel, define the degree of the polynomial as some positive integer >= 1.\n",
    "* C: Regularization parameter. When C is low, the classifier will look for large margins, and will allow for a lot of misclassification. When C is high, the classifier will find a smaller margin, and will penalize misclassification more.\n",
    "\n",
    "**NOTE**: When you finish experimenting in this and the previous block, choose the model you think is the most appropriate, and make sure it is the last model you fit, as we will use it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be34e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the SVM model\n",
    "svm_model_v2 = SVC(kernel='rbf', C=100)  # # You can adjust the kernel and C parameter as needed, but to use polynomial, you need to add a degree paramter\n",
    "svm_model_v2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_pred_test_svm = svm_model_v2.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "conf_matrix_test_svm = confusion_matrix(y_test, y_pred_test_svm)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy_test_svm:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_test_svm)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plot_decision_boundaries(X=X_test_scaled, Y=y_test, predicted_Y=y_pred_test_svm, model=svm_model_v2, label1=label1, label2=label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b7d34",
   "metadata": {},
   "source": [
    "# Simple Hold Out Cross-Validation (Required for 6990 only)\n",
    "\n",
    "In the box below, write a for loop that uses cross validation to select the best value for some parameter.\n",
    "\n",
    "Hints:\n",
    "* Select a parameter to compare (e.g., the degree of the polynomial or C)\n",
    "* Define a list with the values you want to consider.\n",
    "* Write a for loop to iterate over the list, train a model with the current value of the parameter, and record the error on the held out test dataset.\n",
    "* Find which value of the parameter had the lowest error, and print this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02937f5",
   "metadata": {},
   "source": [
    "# Evaluate your selected model on the validation dataset\n",
    "\n",
    "***IMPORTANT: Only run this model once, when you have finalized your decision regarding which model to use! Looking at the results on your validation data and then updating your model is <ins> not cool </ins>***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb95fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model (defined above) that you want to use moving forward\n",
    "my_best_model = svm_model_v2\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_pred_final_val = my_best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_final_val = accuracy_score(y_test, y_pred_final_val)\n",
    "conf_matrix_final_val = confusion_matrix(y_test, y_pred_final_val)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy_final_val:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_final_val)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plot_decision_boundaries(X=X_test_scaled, Y=y_test, predicted_Y=y_pred_final_val, model=my_best_model, label1=label1, label2=label2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
